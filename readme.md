# ğŸ‰ Dragon Dictation Pro

**AI-Powered Medical Transcription System for Vascular Surgery**

Dragon Dictation Pro is a GPU-accelerated medical transcription service that combines OpenAI's Whisper for speech-to-text with Google's Gemini AI for intelligent field extraction into structured procedure notes.

---

## ğŸ¯ Features

- **ğŸ¤ High-Accuracy Transcription**: Whisper medium.en model optimized for medical terminology
- **ğŸ§  Intelligent Field Extraction**: Gemini 1.5 Flash extracts structured data with confidence scores
- **ğŸ“‹ Procedure Macros**: 14 pre-built templates for common vascular procedures
- **âš¡ GPU Acceleration**: CUDA 12.4 support for fast processing
- **ğŸ”„ Automatic Fallback**: Regex-based extraction when AI fails
- **ğŸ¥ Medical Vocabulary**: Custom hotwords for vascular surgery terms
- **ğŸ“Š Confidence Scoring**: Know which extractions are reliable

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Docker Compose                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   PostgreSQL Database    â”‚  Dragon Dictation AI Service â”‚
â”‚   (Port 5432)            â”‚  (Port 5005)                 â”‚
â”‚                          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   - User data            â”‚  â”‚  Whisper (medium.en)   â”‚  â”‚
â”‚   - Transcription logs   â”‚  â”‚  â†“                     â”‚  â”‚
â”‚   - Audit trail          â”‚  â”‚  Gemini 1.5 Flash      â”‚  â”‚
â”‚                          â”‚  â”‚  â†“                     â”‚  â”‚
â”‚                          â”‚  â”‚  Structured Output     â”‚  â”‚
â”‚                          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Prerequisites

- **Docker** & **Docker Compose** installed
- **NVIDIA GPU** with CUDA support (for GPU acceleration)
- **NVIDIA Container Toolkit** installed ([installation guide](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html))
- **Google AI API Key** (get one at [Google AI Studio](https://aistudio.google.com/app/apikey))

### Installation

1. **Clone the repository**
   ```bash
   git clone <your-repo-url>
   cd dragon-dictation-pro
   ```

2. **Create environment file**
   ```bash
   cp .env.example .env
   nano .env  # Edit with your values
   ```

3. **Configure `.env` file**
   ```env
   # PostgreSQL Configuration
   POSTGRES_DB=dragon_db
   POSTGRES_USER=dragon_user
   DB_PASSWORD=your_secure_password_here
   
   # Google Gemini API
   GOOGLE_API_KEY=your_google_api_key_here
   ```

4. **Build and start services**
   ```bash
   docker-compose up --build -d
   ```

5. **Verify deployment**
   ```bash
   # Check service health
   curl http://localhost:5005/
   
   # View logs
   docker-compose logs -f dragon_dictation
   ```

---

## ğŸ“¡ API Endpoints

### `GET /` - Health Check
Check if the service is running.

**Response:**
```json
{
  "status": "healthy",
  "whisper_model": "medium.en",
  "device": "cuda",
  "gemini_enabled": true,
  "macros_loaded": 14
}
```

---

### `POST /transcribe` - Transcribe Audio

Convert audio to text using Whisper.

**Request:**
```bash
curl -X POST http://localhost:5005/transcribe \
  -F "file=@recording.wav"
```

**Response:**
```json
{
  "text": "The patient underwent balloon angioplasty...",
  "segments": [
    {
      "text": "The patient underwent balloon angioplasty",
      "start": 0.0,
      "end": 3.5
    }
  ],
  "language": "en",
  "duration": 15.2,
  "processing_time": 2.3
}
```

---

### `POST /process_note` - Extract Structured Fields

Process transcribed text with AI to extract structured data.

**Request:**
```bash
curl -X POST http://localhost:5005/process_note \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Patient had balloon angioplasty of the left femoral artery on January 15th",
    "macro_key": "arteriogram"
  }'
```

**Response:**
```json
{
  "fields": {
    "date": {
      "value": "January 15th",
      "confidence": 0.95
    },
    "laterality": {
      "value": "left",
      "confidence": 0.98
    },
    "artery": {
      "value": "femoral artery",
      "confidence": 0.92
    },
    "preop_dx": {
      "value": "",
      "confidence": 0.0
    }
  },
  "metadata": {
    "processing_time": 1.8,
    "macro_key": "arteriogram",
    "low_confidence_count": 1
  }
}
```

---

### `GET /list_macros` - List Available Procedures

**Response:**
```json
{
  "macros": [
    "debridement",
    "arteriogram",
    "bilateral_arteriogram",
    "venogram",
    "renal_arteriogram",
    "fistula_creation",
    "shuntogram",
    "thrombectomy",
    "aortogram",
    "varithena",
    "carotid_arteriogram",
    "permcath",
    "toe_amputation",
    "cerebral_arteriogram"
  ],
  "count": 14
}
```

---

### `GET /validate_macro/<macro_key>` - Validate Macro Template

Check which fields a macro requires.

**Example:**
```bash
curl http://localhost:5005/validate_macro/arteriogram
```

**Response:**
```json
{
  "macro_key": "arteriogram",
  "fields": [
    "date",
    "preop_dx",
    "postop_dx",
    "laterality",
    "artery",
    "narrative"
  ],
  "field_count": 6,
  "template_length": 542
}
```

---

## ğŸ“‹ Available Procedure Macros

| Macro Key | Procedure Type |
|-----------|----------------|
| `debridement` | Excisional debridement |
| `arteriogram` | Lower extremity arteriogram with angioplasty |
| `bilateral_arteriogram` | Bilateral arteriogram with stent |
| `venogram` | Ascending venography with IVUS |
| `renal_arteriogram` | Bilateral renal arteriogram |
| `fistula_creation` | Brachiocephalic fistula creation |
| `shuntogram` | Shuntogram with angioplasty |
| `thrombectomy` | Dialysis access thrombectomy |
| `aortogram` | Abdominal aortogram |
| `varithena` | Varicose vein chemical ablation |
| `carotid_arteriogram` | Carotid arteriogram |
| `permcath` | Permcath placement |
| `toe_amputation` | Distal toe amputation |
| `cerebral_arteriogram` | Four vessel cerebral arteriogram |

---

## ğŸ”§ Configuration

### Custom Macros

Add new procedure templates in `dragon_dictation_pro/config/macros.json`:

```json
{
  "my_procedure": "Procedure Date: {date}\n\nPreoperative Diagnosis:\n1. {preop_dx}\n..."
}
```

Fields are defined using `{field_name}` syntax.

### Medical Hotwords

Customize medical vocabulary in `dragon_dictation_pro/config/hotwords.txt`:

```
aneurysm
stenosis
thrombectomy
```

### Model Configuration

Edit `dragon_dictation_pro/dragon_gpu_server.py`:

```python
MODEL_SIZE = "medium.en"  # Options: tiny.en, base.en, small.en, medium.en, large
DEVICE = "cuda"           # Options: cuda, cpu
COMPUTE_TYPE = "float16"  # Options: float16, float32, int8
```

---

## ğŸ³ Docker Commands

```bash
# Start services
docker-compose up -d

# View logs
docker-compose logs -f dragon_dictation

# Restart services
docker-compose restart

# Stop services
docker-compose down

# Rebuild after code changes
docker-compose up --build -d

# Remove all data (WARNING: deletes database)
docker-compose down -v
```

---

## ğŸ” Troubleshooting

### GPU Not Detected

**Error:** `RuntimeError: CUDA not available`

**Solution:**
1. Verify NVIDIA drivers: `nvidia-smi`
2. Install NVIDIA Container Toolkit
3. Restart Docker daemon: `sudo systemctl restart docker`

### Gemini API Errors

**Error:** `GOOGLE_API_KEY not set`

**Solution:**
1. Add API key to `.env` file
2. Restart services: `docker-compose restart dragon_dictation`

### Low Transcription Accuracy

**Solutions:**
- Use higher quality audio (16kHz+, WAV format)
- Add domain-specific terms to `hotwords.txt`
- Upgrade model: `MODEL_SIZE = "large"`
- Ensure proper microphone positioning

### Out of Memory Errors

**Solutions:**
- Reduce model size: `MODEL_SIZE = "small.en"`
- Use `COMPUTE_TYPE = "int8"` for lower memory usage
- Check GPU memory: `nvidia-smi`

---

## ğŸ“Š Performance Benchmarks

**Test Environment:** NVIDIA RTX 3090 (24GB VRAM)

| Model | Processing Time | Memory Usage | Accuracy |
|-------|----------------|--------------|----------|
| tiny.en | 0.5s / min | 1GB | ~85% |
| base.en | 1.2s / min | 1.5GB | ~90% |
| small.en | 2.1s / min | 2GB | ~94% |
| medium.en | 4.8s / min | 5GB | ~96% |
| large | 9.2s / min | 10GB | ~98% |

---

## ğŸ”’ Security Considerations

- **Never commit `.env` file** to version control
- **Use strong database passwords** (20+ characters)
- **Restrict API access** with firewall rules
- **Enable HTTPS** for production deployments
- **Regular security updates**: `docker-compose pull`
- **Audit logs** for HIPAA compliance

### HIPAA Compliance Notes

This system processes Protected Health Information (PHI). For production use:

1. Enable encryption at rest for PostgreSQL volumes
2. Use TLS/SSL for all API communications
3. Implement audit logging for all transcriptions
4. Regular security assessments
5. Business Associate Agreement (BAA) with Google for Gemini API

---

## ğŸ› ï¸ Development

### Project Structure

```
dragon-dictation-pro/
â”œâ”€â”€ docker-compose.yml              # Service orchestration
â”œâ”€â”€ .env                            # Environment variables (create from .env.example)
â”œâ”€â”€ .env.example                    # Template for environment setup
â””â”€â”€ dragon_dictation_pro/
    â”œâ”€â”€ Dockerfile                  # Container build instructions
    â”œâ”€â”€ dragon_gpu_server.py        # Main Flask application
    â”œâ”€â”€ requirements.txt            # Python dependencies
    â””â”€â”€ config/
        â”œâ”€â”€ macros.json            # Procedure templates
        â””â”€â”€ hotwords.txt           # Medical vocabulary
```

### Adding New Features

1. Fork the repository
2. Create feature branch: `git checkout -b feature/new-macro`
3. Make changes and test locally
4. Submit pull request

---

## ğŸ“ Example Workflow

Complete transcription pipeline:

```bash
# 1. Record audio (from your application)
# audio_file = "procedure_recording.wav"

# 2. Transcribe audio
curl -X POST http://localhost:5005/transcribe \
  -F "file=@procedure_recording.wav" \
  -o transcription.json

# 3. Extract transcript text
TRANSCRIPT=$(cat transcription.json | jq -r '.text')

# 4. Process with macro
curl -X POST http://localhost:5005/process_note \
  -H "Content-Type: application/json" \
  -d "{
    \"text\": \"$TRANSCRIPT\",
    \"macro_key\": \"arteriogram\"
  }" \
  -o structured_note.json

# 5. View results
cat structured_note.json | jq '.'
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Follow existing code style
2. Add tests for new features
3. Update documentation
4. Submit detailed pull requests

---

## ğŸ“„ License

[Your License Here]

---

## ğŸ‘¥ Support

- **Issues**: [GitHub Issues]
- **Documentation**: This README
- **Email**: trippmorgan@yourdomain.com

---

## ğŸ™ Acknowledgments

- **OpenAI Whisper** - Speech recognition model
- **Google Gemini** - Language model for field extraction
- **faster-whisper** - Optimized Whisper implementation
- **NVIDIA CUDA** - GPU acceleration

---

**Built with â¤ï¸ for medical professionals**













# Dragon Dictation Pro v7.0 ğŸ¤ğŸ¥

**AI-Powered Medical Transcription with Gemini 2.5 Flash**

Enhanced medical transcription system for vascular surgery procedures featuring dynamic template generation, batch processing, real-time transcription, and comprehensive quality metrics.

---

## ğŸ†• What's New in v7.0

### Major Features
- **Gemini 2.5 Flash** - Upgraded from Gemini 1.5 for superior medical context understanding
- **Dynamic Template Generation** - AI creates custom templates on-the-fly
- **Auto Template Selection** - AI recommends the best template for each procedure
- **Batch Processing** - Process multiple audio files simultaneously
- **Real-time Transcription** - WebSocket support for live dictation
- **Quality Metrics** - Track accuracy, identify problematic templates, monitor performance
- **Template Version Control** - Manage template evolution over time

---

## ğŸ“‹ Table of Contents

1. [System Requirements](#system-requirements)
2. [Quick Start](#quick-start)
3. [Installation](#installation)
4. [Configuration](#configuration)
5. [Database Setup](#database-setup)
6. [API Documentation](#api-documentation)
7. [Integration Guide](#integration-guide)
8. [Quality Monitoring](#quality-monitoring)
9. [Troubleshooting](#troubleshooting)
10. [Migration from v6.0](#migration-from-v60)

---

## ğŸ–¥ï¸ System Requirements

### Hardware
- **GPU**: NVIDIA GPU with 8GB+ VRAM (RTX 3070 or better recommended)
- **CUDA**: Version 12.4+
- **RAM**: 16GB minimum, 32GB recommended
- **Storage**: 50GB free space for models and data

### Software
- **Docker**: Version 24.0+
- **Docker Compose**: Version 2.20+
- **NVIDIA Container Toolkit**: Latest version
- **PostgreSQL**: 15+ (managed by Docker Compose)

### API Keys
- **Google API Key** with Gemini 2.0 Flash access

---

## ğŸš€ Quick Start

```bash
# 1. Clone repository
git clone <repository-url>
cd dragon_dictation_pro

# 2. Create environment file
cat > .env << EOF
POSTGRES_DB=surgical_command_center
POSTGRES_USER=postgres
DB_PASSWORD=your_secure_password_here
GOOGLE_API_KEY=your_gemini_api_key_here
EOF

# 3. Build and start services
docker-compose up -d

# 4. Initialize database (first time only)
docker exec -i central_postgres_db psql -U postgres -d surgical_command_center < database_schema.sql

# 5. Verify services
curl http://localhost:5005/
```

Expected response:
```json
{
  "status": "healthy",
  "version": "7.0",
  "gemini_model": "gemini-2.0-flash-exp",
  "features": [...]
}
```

---

## ğŸ“¦ Installation

### Step 1: NVIDIA Docker Setup

```bash
# Install NVIDIA Container Toolkit
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \
    sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update
sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker

# Verify GPU access
docker run --rm --gpus all nvidia/cuda:12.4.1-base-ubuntu22.04 nvidia-smi
```

### Step 2: Project Setup

```bash
# Create project directory structure
dragon_dictation_pro/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ database_schema.sql
â”œâ”€â”€ dragon_dictation_pro/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ dragon_gpu_server.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ config/
â”‚       â”œâ”€â”€ macros.json
â”‚       â””â”€â”€ hotwords.txt
â””â”€â”€ client/
    â”œâ”€â”€ dragon_client.py
    â””â”€â”€ examples.py
```

### Step 3: Configuration

Create `.env` file:
```bash
# Database Configuration
POSTGRES_DB=surgical_command_center
POSTGRES_USER=postgres
DB_PASSWORD=ChangeMe_SecurePassword123!

# Gemini AI Configuration
GOOGLE_API_KEY=AIzaSy...your_actual_api_key

# Optional: Performance Tuning
WHISPER_MODEL=medium.en
COMPUTE_TYPE=float16
BEAM_SIZE=5
```

### Step 4: Build and Deploy

```bash
# Build images
docker-compose build

# Start services
docker-compose up -d

# View logs
docker-compose logs -f dragon_dictation

# Check container status
docker-compose ps
```

---

## ğŸ—„ï¸ Database Setup

### Initial Schema Creation

```bash
# Copy schema file to container
docker cp database_schema.sql central_postgres_db:/tmp/

# Execute schema
docker exec -i central_postgres_db psql -U postgres -d surgical_command_center < database_schema.sql

# Verify tables
docker exec -it central_postgres_db psql -U postgres -d surgical_command_center -c "\dt"
```

### Database Backup

```bash
# Create backup
docker exec central_postgres_db pg_dump -U postgres surgical_command_center > backup_$(date +%Y%m%d).sql

# Restore from backup
docker exec -i central_postgres_db psql -U postgres surgical_command_center < backup_20251022.sql
```

---

## ğŸ“¡ API Usage Examples

### Python Client

```python
from dragon_client import DragonClient

# Initialize client
client = DragonClient("http://localhost:5005")

# Check health
health = client.health_check()
print(f"Status: {health['status']}")

# Transcribe audio
with open('procedure.wav', 'rb') as audio:
    result = client.transcribe_and_process(
        audio,
        auto_select_template=True,
        confidence_threshold=0.75
    )

if result['status'] == 'success':
    print(f"Template: {result['template_used']}")
    print(f"Confidence: {result['note']['metadata']['avg_confidence']:.2%}")
```

### cURL Examples

```bash
# Health check
curl http://localhost:5005/

# Transcribe audio
curl -X POST http://localhost:5005/transcribe \
  -F "file=@procedure.wav"

# Select template
curl -X POST http://localhost:5005/select_template \
  -H "Content-Type: application/json" \
  -d '{"text": "Patient underwent bilateral arteriogram..."}'

# Generate dynamic template
curl -X POST http://localhost:5005/generate_dynamic_template \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Complex vascular procedure...",
    "procedure_type": "Custom Intervention"
  }'

# Get quality metrics
curl "http://localhost:5005/metrics?days=30"
```

---

## ğŸ”— Surgical Command Center Integration

### Database Integration

```python
import psycopg2
from dragon_client import DragonClient, SurgicalCommandCenterIntegration

# Connect to database
db_conn = psycopg2.connect(
    host="localhost",
    port=5432,
    database="surgical_command_center",
    user="postgres",
    password="your_password"
)

# Initialize integration
integration = SurgicalCommandCenterIntegration(
    dragon_url="http://localhost:5005",
    db_connection=db_conn
)

# Process procedure with auto-save
with open('procedure.wav', 'rb') as audio:
    result = integration.process_procedure_recording(
        audio_file=audio,
        patient_id="PAT-12345",
        procedure_id="PROC-67890",
        surgeon_id="DR-MORGAN",
        auto_save=True
    )

print(f"Saved to database: {result['database_saved']}")
```

### Flask API Integration

```python
from flask import Flask, request, jsonify
from dragon_client import WebAPIHandler, DragonClient, SurgicalCommandCenterIntegration

app = Flask(__name__)

# Setup
dragon = DragonClient("http://localhost:5005")
db_integration = SurgicalCommandCenterIntegration("http://localhost:5005", db_conn)
api_handler = WebAPIHandler(app, dragon, db_integration)

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8000)
```

Now your surgical command center has endpoints:
- `POST /api/v1/procedure/transcribe` - Upload and process procedures
- `GET /api/v1/procedure/<id>/history` - View procedure history
- `POST /api/v1/procedure/correct` - Submit corrections
- `GET /api/v1/quality/report` - Quality metrics

---

## ğŸ“Š Quality Monitoring

### View Current Metrics

```bash
# Get 30-day report
curl "http://localhost:5005/metrics?days=30" | jq .

# Database query for trends
docker exec -it central_postgres_db psql -U postgres -d surgical_command_center
```

```sql
-- View accuracy trends
SELECT * FROM v_accuracy_trend LIMIT 10;

-- View problematic templates
SELECT * FROM identify_problematic_templates(10, 0.65, 0.20);

-- User productivity
SELECT * FROM v_user_productivity WHERE user_id = 'DR-MORGAN';

-- Daily quality trends
SELECT * FROM v_daily_quality_trends WHERE date > CURRENT_DATE - 30;
```

### Automated Quality Alerts

```python
from dragon_client import QualityMonitor, PRODUCTION_CONFIG

monitor = QualityMonitor(PRODUCTION_CONFIG)

# Run periodic check
metrics = client.get_metrics(days=7)
alerts = monitor.check_and_alert(metrics)

for alert in alerts:
    print(f"[{alert['severity']}] {alert['message']}")
    # Send to Slack, email, etc.
```

---

## ğŸ” Troubleshooting

### Service Won't Start

```bash
# Check logs
docker-compose logs dragon_dictation

# Common issues:
# 1. GPU not detected
docker run --rm --gpus all nvidia/cuda:12.4.1-base-ubuntu22.04 nvidia-smi

# 2. Out of memory
# Reduce model size in .env:
WHISPER_MODEL=small.en

# 3. Port conflict
# Change port in docker-compose.yml:
ports:
  - "5006:5005"  # Use 5006 instead
```

### Low Transcription Quality

1. **Check audio quality**: Ensure clear audio, minimal background noise
2. **Verify confidence scores**: Check `/metrics` endpoint
3. **Review hotwords**: Add domain-specific terms to `config/hotwords.txt`
4. **Adjust beam size**: Increase in `dragon_gpu_server.py` (line 81)

### Template Issues

```bash
# Identify problematic templates
curl "http://localhost:5005/metrics?days=30" | jq '.template_stats.problematic_templates'

# Validate template structure
curl "http://localhost:5005/validate_macro/arteriogram"

# Generate new template
curl -X POST http://localhost:5005/generate_dynamic_template \
  -H "Content-Type: application/json" \
  -d '{"text": "...", "procedure_type": "..."}'
```

### Database Connection Issues

```bash
# Check PostgreSQL status
docker-compose ps postgres

# Test connection
docker exec -it central_postgres_db psql -U postgres -d surgical_command_center -c "SELECT version();"

# Reset database (âš ï¸ deletes all data)
docker-compose down -v
docker-compose up -d
# Re-run schema
docker exec -i central_postgres_db psql -U postgres -d surgical_command_center < database_schema.sql
```

---

## ğŸ”„ Migration from v6.0

### Breaking Changes
âœ… **None** - v7.0 is fully backward compatible

### New Features to Adopt

1. **Update Gemini Model Reference**
```python
# Old (v6.0)
genai.GenerativeModel('gemini-1.5-flash')

# New (v7.0)
genai.GenerativeModel('gemini-2.0-flash-exp')
```

2. **Add New Dependencies**
```bash
pip install flask-socketio python-socketio eventlet
```

3. **Database Schema Updates**
```bash
# Apply new tables and functions
docker exec -i central_postgres_db psql -U postgres -d surgical_command_center < database_schema.sql
```

4. **Update Environment Variables**
```bash
# Add to .env if needed
WHISPER_MODEL=medium.en
COMPUTE_TYPE=float16
```

### Migration Steps

```bash
# 1. Backup current data
docker exec central_postgres_db pg_dump -U postgres surgical_command_center > backup_v6.sql

# 2. Stop v6.0 services
docker-compose down

# 3. Update code
git pull origin main

# 4. Rebuild images
docker-compose build

# 5. Start v7.0
docker-compose up -d

# 6. Apply database migrations
docker exec -i central_postgres_db psql -U postgres -d surgical_command_center < database_schema.sql

# 7. Verify
curl http://localhost:5005/ | jq '.version'
# Should return "7.0"
```

---

## ğŸ›¡ï¸ Security Best Practices

### Production Deployment

1. **Enable HTTPS**: Use nginx reverse proxy with SSL
2. **API Authentication**: Implement JWT or API keys
3. **Database Security**: Use strong passwords, enable SSL connections
4. **Network Isolation**: Use Docker networks, firewall rules
5. **PHI Compliance**: Ensure HIPAA compliance for patient data
6. **API Rate Limiting**: Prevent abuse

### Example nginx Configuration

```nginx
server {
    listen 443 ssl;
    server_name dragon.yourhospital.com;

    ssl_certificate /path/to/cert.pem;
    ssl_certificate_key /path/to/key.pem;

    location / {
        proxy_pass http://localhost:5005;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }

    # WebSocket support
    location /socket.io {
        proxy_pass http://localhost:5005;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}